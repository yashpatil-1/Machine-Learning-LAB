# 🤖 Machine Learning (ML) Experiments

## 🚀 Overview
This repository contains a series of **Machine Learning (ML) experiments** performed as part of academic coursework. The experiments explore various ML concepts, implementations, and evaluations using **Jupyter Notebooks and reports**. Below is a summary of the tasks covered in these experiments.
This repository contains a series of **Machine Learning (ML) experiments** performed as part of academic coursework. The experiments explore various ML concepts, implementations, and evaluations using **Jupyter Notebooks and reports**.

## 📂 Project Structure

### 🔍 Experiments Overview
1. **Python Libraries & Data Handling**
   - Study of Python packages: NumPy, Pandas, Matplotlib
   - Perform Exploratory Data Analysis (EDA) on real-world datasets
   - Read different types of data files (CSV, Excel, Text, etc.)
   - Obtain metadata of a dataset
   - Handle missing values
   - Work with categorical data (mapping ordinal features, encoding labels, one-hot encoding)
   - Apply variable transformation and feature selection

2. **Data Visualization**
   - Analyze data using Matplotlib
   - Identify trends, patterns, and outliers with different types of graphs

3. **Data Preprocessing**
   - Apply pre-processing techniques using scikit-learn
   - Transform raw features into suitable representations for machine learning models

4. **Regression Models**
   - Implement Simple and Multiple Linear Regression on real-world datasets
   - Analyze the effect of varying learning rates and iterations
   - Implement Gradient Descent using NumPy on a toy dataset
   - Implement Linear Regression using scikit-learn
   - Examine the effect of penalizing parameters

5. **Classification Models**
   - Implement Logistic Regression using scikit-learn
   - Calculate class probabilities
   - Evaluate performance using a confusion matrix

6. **Decision Trees & Ensemble Learning**
   - Implement Decision Tree Classification algorithm
   - Apply Ensemble Learning techniques (Random Forest, AdaBoost, XGBoost)
   - Reduce overfitting in Decision Trees
   - Compare Decision Tree vs. Ensemble Learning performance

7. **Support Vector Machines (SVM)**
   - Implement SVM classification algorithm
   - Measure accuracy by varying kernels
   - Tune the model using regularization and gamma parameters

8. **Clustering**
   - Implement K-Means Clustering
   - Analyze the effect of varying the number of clusters

9. **Recommendation Systems**
   - Implement a recommendation system using the Nearest Neighbor algorithm

---
The repository includes the following files:

### 📜 Jupyter Notebooks (`.ipynb`)
- **A176_Yash_Patil_ML_Lab2.ipynb** – Lab 2 Implementation
- **ML_Lab_3.ipynb** – Lab 3 Implementation
- **ML_Lab_4.ipynb** – Lab 4 Implementation
- **A176_Yash_Patil_ML_Prac_6.ipynb** – Practical 6 Implementation

### 📄 Reports (`.pdf`)
- **ML exp1 A176.pdf** – Report for Experiment 1
- **ML EXP4.pdf** – Report for Experiment 4
- **ML Exp 6.pdf** – Report for Experiment 6
- **ML Graphs Exp 3.pdf** – Graphs for Experiment 3
- **A176_ML-Lab3.pdf** – Lab 3 Documentation
- **A176_Yash_Patil_ML_Exp5.pdf** – Report for Experiment 5

## 🛠️ Technologies Used
- **Python** 🐍
- **Jupyter Notebook** 📓
- **Machine Learning Libraries:** NumPy, Pandas, Matplotlib, Scikit-learn

## 🔬 Experiments Conducted

### 📊 Exploratory Data Analysis (EDA) & Preprocessing
- Study of different Python packages: NumPy, Pandas, Matplotlib
- Perform **Exploratory Data Analysis (EDA)** on real-world datasets
- Read different data file formats: **CSV, Excel, Text Files**
- Obtain metadata and handle **missing values**
- Handling categorical data: **Ordinal Mapping, Encoding, One-Hot Encoding**
- **Variable Transformation & Feature Selection**

### 📈 Data Visualization & Trends Analysis
- Analyze data using **Matplotlib** and identify **trends, patterns, outliers**

### 🔄 Machine Learning Model Implementations
- **Linear Regression (Simple & Multiple):**
  - Implement regression using **Scikit-learn**
  - Analyze the effect of **learning rate & iterations**
  - Implement **Gradient Descent Algorithm** manually
  - Examine the effect of **penalizing parameters**
- **Logistic Regression:**
  - Train on real-world datasets using **Scikit-learn**
  - Calculate **class probability** and evaluate with a **confusion matrix**
- **Decision Tree & Ensemble Learning:**
  - Implement **Decision Trees, Random Forest, AdaBoost, XGBoost**
  - Identify & reduce **overfitting**
  - Compare outputs of **Decision Trees vs. Ensemble Learning**
- **Support Vector Machines (SVM):**
  - Train **SVM classifiers** and measure accuracy by varying **kernels**
  - Tune model using **regularization & gamma parameters**
- **K-Means Clustering:**
  - Implement **K-Means** and analyze **varying cluster numbers**
- **Recommendation Systems:**
  - Build a **recommendation system** using **Nearest Neighbors**

## ▶️ How to Run the Notebooks
1. Clone this repository:
   ```bash
   git clone https://github.com/yashpatil-1/ml-experiments.git
   cd ml-experiments
   ```
2. Install required dependencies:
   ```bash
   pip install numpy pandas matplotlib scikit-learn
   ```
3. Open Jupyter Notebook:
   ```bash
   jupyter notebook
   ```
4. Navigate to the desired `.ipynb` file and run the cells.

## 📸 Screenshots / Graphs
*(Add images or plots from experiments if needed)*

## 🤝 Contributing
Feel free to fork this repository, improve implementations, and submit pull requests.

## 📜 License
This project is licensed under the **MIT License**.

## 📞 Contact
For any queries, reach out via **[workwithme.3215@gmail.com](mailto:workwithme.3215@gmail.com)** or visit my **[GitHub Profile](https://github.com/yashpatil-1)**.

---
🚀 **Happy Learning & Experimenting with ML!**
